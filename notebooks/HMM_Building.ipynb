{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hidden Markov Model (HMM) Workshop \n",
    "## Sara Carioscia and Dylan Taylor\n",
    "### Hosted by Agara Bio"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here you'll write your pseudocode for each of our prompts as we discuss. Then, you'll follow along with us as we write the code OR just copy the relevant code from `HMM_Building_Key` that corresponds with your pseudocode. We'll go through this step-by-step to ensure we all understand a) in theory what you'd like to do for your model and b) how the actual Python code is implementing your vision."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1: Getting started\n",
    "Because we'll be working primarily with arrays, we'll need to import the `numpy` library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The data is encoded as indicies so that we can more easily look up the values we need from our various probability arrays (start, emission, and transition). We won't be interacting directly with the below dictionaries, but they show you how the data is encoded."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_nuc_index = {\n",
    "    'A' : 0,\n",
    "    'C' : 1,\n",
    "    'G' : 2,\n",
    "    'T' : 3\n",
    "}\n",
    "\n",
    "get_state_index = {\n",
    "    'intergenic' : 0,\n",
    "    'start1' : 1,\n",
    "    'start2' : 2,\n",
    "    'start3' : 3,\n",
    "    'exon1' : 4,\n",
    "    'exon2' : 5,\n",
    "    'exon3' : 6,\n",
    "    'intron1' : 7,\n",
    "    'intron2' : 8,\n",
    "    'intron3' : 9,\n",
    "    'stop1' : 10,\n",
    "    'stop2' : 11,\n",
    "    'stop3' : 12\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2: Read in the data\n",
    "Now we need to read in the encoded training data (both DNA sequences and state paths) and store them in numpy arrays."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'numpy' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-8af3f1eddb40>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mDNA_training_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnumpy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'training_data/HMM_DNA_training.npy'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mState_training_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnumpy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'HMM_State_training.npy'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'numpy' is not defined"
     ]
    }
   ],
   "source": [
    "DNA_training_data = numpy.load('training_data/HMM_DNA_training.npy')\n",
    "State_training_data = numpy.load('training_data/HMM_State_training.npy')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3: Learn training values to use in our model\n",
    "From the data we just read in, we need to figure out start counts, emission counts, and transition counts.\n",
    "\n",
    "![Inferring Probabilities](images/inferring_probabilities.png)\n",
    "\n",
    "If we store this data in arrays, how big will each array need to be?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# emission counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# transition counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# start counts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we've initialized our arrays, let's actually pull these counts from the training data arrays"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Can we iterate through both the DNA_training_data array\n",
    "# and the State_training_data array at the same time?\n",
    "# Hint: Are they the same shape?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We had some issues with this function taking too long to run, so if this is the case for you, stop the code cell, and just load in the counts by running the cell below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "emission_counts = numpy.load('model_outputs/emission_counts.npy')\n",
    "transition_counts = numpy.load('model_outputs/transition_counts.npy')\n",
    "start_counts = numpy.load('model_outputs/start_counts.npy')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Great! Now we have our counts, but to use this information in an HMM, we need to convert it to probabilities."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# emission probabilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# transition probabilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# start probabilities"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 4: The Forward Algorithm\n",
    "Because we're potentially going to be using the forward algorithm on multiple models (spoiler alert: we will be), we'd like to make our algorithm a function, so we can use it multiple times without having to rewrite code.\n",
    "\n",
    "![Forward Algorithm](forward_alg_graphic.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def forward_alg():# what inputs does our function need to take?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Theoretically, our function is working! Let's run it on a test sequence to make sure. We can load in a 400 bp sequence to test it on. This sequence, like the training data, has already been encoded for us, so we don't need to worry about that."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_seq = numpy.load('training_data/DNA_test_sequence.npy')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's run our function on our `test_seq` along with the right probabilities."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_model_test_prob = forward_alg()\n",
    "# What arguments are we going to pass to our function?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 5: Comparing to a null model\n",
    "This test sequence comes from an exonic region in a real human gene, so we would hope that our model would be able to pick up on that. The probability we get from the forward algorithm on it's own isn't very useful, so we need to compare it to the probability from a null model. Let's make a null model to run our test sequence on."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# What does the null model look like? What components does it have?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have our null model, let's re-run the forward algorithm on the `test_seq` using this model. Aren't you glad we made it a function!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "null_model_test_prob = forward_alg() # What arguments are we going to pass to our function?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have our two probabilities, let's compare them using log-odds."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
